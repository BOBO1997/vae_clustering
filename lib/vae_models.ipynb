{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoderのモデルを定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "import numpy as np\n",
    "# import os\n",
    "# import pickle\n",
    "# from PIL import Image\n",
    "# from pprint import pprint\n",
    "# import random\n",
    "# import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from torch.utils.data.sampler import SubsetRandomSampler\n",
    "# import torchvision\n",
    "# from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseAE(nn.Module):\n",
    "    def __init__(self, img_size):\n",
    "        super().__init__()\n",
    "        self.img_size = img_size\n",
    "        ## encoder layers ##\n",
    "        self.linear1 = nn.Linear(self.img_size * self.img_size, self.img_size // 4 * self.img_size // 4)\n",
    "        \n",
    "        ## decoder layers ##\n",
    "        self.linear2 = nn.Linear(self.img_size // 4 * self.img_size // 4, self.img_size * self.img_size)\n",
    "\n",
    "    def forward(self, x, get_hidden = False):\n",
    "        ## encode ## \n",
    "        x = self.linear1(x)\n",
    "        if get_hidden:\n",
    "            return torch.flatten(x)\n",
    "        \n",
    "        ## decode ##\n",
    "        x = self.linear2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseAE_2dim(nn.Module):\n",
    "    \n",
    "    def __init__(self, img_size):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(img_size * img_size,  1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1024, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 12),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(12, 2))\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2, 12),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(12, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1024, 128 * 128),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoEncoder: MaxPoolなし(2020.06.17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAE(nn.Module):\n",
    "    def __init__(self, img_size):\n",
    "        super().__init__()\n",
    "        self.img_size = img_size\n",
    "        ## encoder layers ##\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=5, padding=2, stride=2) # conv layer, 5x5 kernels, input: 1 * 128 * 128, output: 8 * 64 * 64\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=5, padding=2, stride=2) # conv layer, 5x5 kernels, input: 8 * 64 * 64, output: 16 * 32 * 32\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=5, padding=2, stride=2) # conv layer, 5x5 kernels, input: 16 * 32 * 32, output: 32 * 16 * 16\n",
    "        self.conv4 = nn.Conv2d(32, 64, kernel_size=3, padding=1, stride=2) # conv layer, 3x3 kernels, input: 32 * 16 * 16, output: 64 * 8 * 8\n",
    "        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, padding=1, stride=2) # conv layer, 3x3 kernels, input: 64 * 8 * 8, output: 128 * 4 * 4\n",
    "        self.conv6 = nn.Conv2d(128, 64, kernel_size=4) # conv layer, 4x4 kernels, input: 128 * 4 * 4, output: 64 * 1 * 1\n",
    "        \n",
    "        ## decoder layers ##\n",
    "        self.t_conv6 = nn.ConvTranspose2d(64, 128, kernel_size=4, stride=1)\n",
    "        self.t_conv5 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2)\n",
    "        self.t_conv4 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2)\n",
    "        self.t_conv3 = nn.ConvTranspose2d(32, 16, kernel_size=5, stride=2)\n",
    "        self.t_conv2 = nn.ConvTranspose2d(16, 8, kernel_size=5, stride=2)\n",
    "        self.t_conv1 = nn.ConvTranspose2d(8, 1, kernel_size=5, stride=2)\n",
    "\n",
    "    def forward(self, x, get_hidden = False):\n",
    "        ## encode ##\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        if get_hidden:\n",
    "            return x.flatten()\n",
    "        \n",
    "        ## decode ##\n",
    "        x = F.relu(self.t_conv6(x))\n",
    "        x = F.relu(self.t_conv5(x))[:, :, :-1, :-1]\n",
    "        x = F.relu(self.t_conv4(x))[:, :, :-1, :-1]\n",
    "        x = F.relu(self.t_conv3(x))[:, :, 1:-2, 1:-2]\n",
    "        x = F.relu(self.t_conv2(x))[:, :, 1:-2, 1:-2]\n",
    "        x = self.t_conv1(x)[:, :, 1:-2, 1:-2]\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAE_deep(nn.Module):\n",
    "    def __init__(self, img_size):\n",
    "        super().__init__()\n",
    "        self.img_size = img_size\n",
    "        ## encoder layers ##\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=5, padding=2, stride=2) # conv layer, 5x5 kernels, input: 1 * 128 * 128, output: 8 * 64 * 64\n",
    "        self.conv2 = nn.Conv2d(8, 32, kernel_size=5, padding=2, stride=2) # conv layer, 5x5 kernels, input: 8 * 64 * 64, output: 16 * 32 * 32\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=5, padding=2, stride=2) # conv layer, 5x5 kernels, input: 16 * 32 * 32, output: 32 * 16 * 16\n",
    "        self.conv4 = nn.Conv2d(64, 256, kernel_size=3, padding=1, stride=2) # conv layer, 3x3 kernels, input: 32 * 16 * 16, output: 64 * 8 * 8\n",
    "        self.conv5 = nn.Conv2d(256, 1024, kernel_size=3, padding=1, stride=2) # conv layer, 3x3 kernels, input: 64 * 8 * 8, output: 128 * 4 * 4\n",
    "        self.conv6 = nn.Conv2d(1024, 64, kernel_size=4) # conv layer, 4x4 kernels, input: 128 * 4 * 4, output: 64 * 1 * 1\n",
    "        \n",
    "        ## decoder layers ##\n",
    "        self.t_conv6 = nn.ConvTranspose2d(64, 1024, kernel_size=4, stride=1)\n",
    "        self.t_conv5 = nn.ConvTranspose2d(1024, 256, kernel_size=3, stride=2)\n",
    "        self.t_conv4 = nn.ConvTranspose2d(256, 64, kernel_size=3, stride=2)\n",
    "        self.t_conv3 = nn.ConvTranspose2d(64, 32, kernel_size=5, stride=2)\n",
    "        self.t_conv2 = nn.ConvTranspose2d(32, 8, kernel_size=5, stride=2)\n",
    "        self.t_conv1 = nn.ConvTranspose2d(8, 1, kernel_size=5, stride=2)\n",
    "\n",
    "    def forward(self, x, get_hidden = False):\n",
    "        ## encode ##\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        if get_hidden:\n",
    "            return x.flatten()\n",
    "        \n",
    "        ## decode ##\n",
    "        x = F.relu(self.t_conv6(x))\n",
    "        x = F.relu(self.t_conv5(x))[:, :, :-1, :-1]\n",
    "        x = F.relu(self.t_conv4(x))[:, :, :-1, :-1]\n",
    "        x = F.relu(self.t_conv3(x))[:, :, 1:-2, 1:-2]\n",
    "        x = F.relu(self.t_conv2(x))[:, :, 1:-2, 1:-2]\n",
    "        x = self.t_conv1(x)[:, :, 1:-2, 1:-2]\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAE_2dim(nn.Module):\n",
    "    def __init__(self, img_size, binary = False):\n",
    "        super().__init__()\n",
    "        self.img_size = img_size\n",
    "        self.binary = binary\n",
    "        ## encoder layers ##\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=5, padding=2, stride=2) # conv layer, 5x5 kernels, input: 1 * 128 * 128, output: 8 * 64 * 64\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=5, padding=2, stride=2) # conv layer, 5x5 kernels, input: 8 * 64 * 64, output: 16 * 32 * 32\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=5, padding=2, stride=2) # conv layer, 5x5 kernels, input: 16 * 32 * 32, output: 32 * 16 * 16\n",
    "        self.conv4 = nn.Conv2d(32, 64, kernel_size=3, padding=1, stride=2) # conv layer, 3x3 kernels, input: 32 * 16 * 16, output: 64 * 8 * 8\n",
    "        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, padding=1, stride=2) # conv layer, 3x3 kernels, input: 64 * 8 * 8, output: 128 * 4 * 4\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=4) # conv layer, 4x4 kernels, input: 128 * 4 * 4, output: 2 * 1 * 1\n",
    "        self.conv7 = nn.Conv2d(128, 2, kernel_size=1) # conv layer, 4x4 kernels, input: 128 * 4 * 4, output: 2 * 1 * 1\n",
    "        # self.linear = nn.Linear(64, 2)\n",
    "        \n",
    "        ## decoder layers ##\n",
    "        # self.t_linear = nn.Linear(2, 64)\n",
    "        self.t_conv7 = nn.ConvTranspose2d(2, 128, kernel_size=1, stride=1)\n",
    "        self.t_conv6 = nn.ConvTranspose2d(128, 128, kernel_size=4, stride=1)\n",
    "        self.t_conv5 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2)\n",
    "        self.t_conv4 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2)\n",
    "        self.t_conv3 = nn.ConvTranspose2d(32, 16, kernel_size=5, stride=2)\n",
    "        self.t_conv2 = nn.ConvTranspose2d(16, 8, kernel_size=5, stride=2)\n",
    "        self.t_conv1 = nn.ConvTranspose2d(8, 1, kernel_size=5, stride=2)\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = F.relu(self.conv7(x))\n",
    "        return x\n",
    "        \n",
    "    def decoder(self, x):\n",
    "        x = F.relu(self.t_conv7(x))\n",
    "        x = F.relu(self.t_conv6(x))\n",
    "        x = F.relu(self.t_conv5(x))[:, :, :-1, :-1]\n",
    "        x = F.relu(self.t_conv4(x))[:, :, :-1, :-1]\n",
    "        x = F.relu(self.t_conv3(x))[:, :, 1:-2, 1:-2]\n",
    "        x = F.relu(self.t_conv2(x))[:, :, 1:-2, 1:-2]\n",
    "        x = self.t_conv1(x)[:, :, 1:-2, 1:-2]\n",
    "        x = torch.sigmoid(x) if self.binary else torch.sigmoid(x) # 要修正 # 二値化\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        # x = F.relu(self.linear(x.view(-1, 64)))\n",
    "        # x = F.relu(self.t_linear(x))\n",
    "        # x = F.relu(self.t_conv6(x.view(-1, 64, 1, 1)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAE_2dim_alta(nn.Module):\n",
    "    def __init__(self, img_size, binary = False):\n",
    "        super().__init__()\n",
    "        self.img_size = img_size\n",
    "        self.binary = binary\n",
    "        ## encoder layers ##\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=5, padding=2, stride=2) # conv layer, 5x5 kernels, input: 1 * 128 * 128, output: 8 * 64 * 64\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=5, padding=2, stride=2) # conv layer, 5x5 kernels, input: 8 * 64 * 64, output: 16 * 32 * 32\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=5, padding=2, stride=2) # conv layer, 5x5 kernels, input: 16 * 32 * 32, output: 32 * 16 * 16\n",
    "        self.conv4 = nn.Conv2d(32, 64, kernel_size=3, padding=1, stride=2) # conv layer, 3x3 kernels, input: 32 * 16 * 16, output: 64 * 8 * 8\n",
    "        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, padding=1, stride=2) # conv layer, 3x3 kernels, input: 64 * 8 * 8, output: 128 * 4 * 4\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=4) # conv layer, 4x4 kernels, input: 128 * 4 * 4, output: 2 * 1 * 1\n",
    "        self.conv7 = nn.Conv2d(128, 2, kernel_size=1) # conv layer, 4x4 kernels, input: 128 * 4 * 4, output: 2 * 1 * 1\n",
    "        # self.linear = nn.Linear(64, 2)\n",
    "        \n",
    "        ## decoder layers ##\n",
    "        # self.t_linear = nn.Linear(2, 64)\n",
    "        self.t_conv7 = nn.ConvTranspose2d(2, 128, kernel_size=1, stride=1)\n",
    "        self.t_conv6 = nn.ConvTranspose2d(128, 128, kernel_size=4, stride=1)\n",
    "        self.t_conv5 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2)\n",
    "        self.t_conv4 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2)\n",
    "        self.t_conv3 = nn.ConvTranspose2d(32, 16, kernel_size=5, stride=2)\n",
    "        self.t_conv2 = nn.ConvTranspose2d(16, 8, kernel_size=5, stride=2)\n",
    "        self.t_conv1 = nn.ConvTranspose2d(8, 1, kernel_size=5, stride=2)\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = F.relu(self.conv7(x))\n",
    "        return x\n",
    "        \n",
    "    def decoder(self, x):\n",
    "        x = F.relu(self.t_conv7(x))\n",
    "        x = F.relu(self.t_conv6(x))\n",
    "        x = F.relu(self.t_conv5(x))[:, :, :-1, :-1]\n",
    "        x = F.relu(self.t_conv4(x))[:, :, :-1, :-1]\n",
    "        x = F.relu(self.t_conv3(x))[:, :, 1:-2, 1:-2]\n",
    "        x = F.relu(self.t_conv2(x))[:, :, 1:-2, 1:-2]\n",
    "        x = self.t_conv1(x)[:, :, 1:-2, 1:-2]\n",
    "        x = torch.sigmoid(x) if self.binary else torch.sigmoid(x) # 要修正 # 二値化\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        # x = F.relu(self.linear(x.view(-1, 64)))\n",
    "        # x = F.relu(self.t_linear(x))\n",
    "        # x = F.relu(self.t_conv6(x.view(-1, 64, 1, 1)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAE_mnist(nn.Module):\n",
    "    def __init__(self, img_size):\n",
    "        super().__init__()\n",
    "        self.img_size = img_size\n",
    "        ## encoder layers ##\n",
    "        self.conv1 = nn.Conv2d(1, 2, 3, padding=1) # conv layer (channel from 1 --> 2), 3x3 kernels, input: 1 * 28 * 28,\n",
    "        self.conv2 = nn.Conv2d(2, 3, 3, padding=1) # conv layer (channel from 2 --> 3), 3x3 kernels, input: 2 * 14 * 14\n",
    "        self.pool = nn.MaxPool2d(2, 2) # pooling layer to reduce x-y dims by two; kernel and stride of 2\n",
    "        \n",
    "        ## decoder layers ##\n",
    "        ## a kernel of 2 and a stride of 2 will increase the spatial dims by 2\n",
    "        self.t_conv4 = nn.ConvTranspose2d(3, 2, 2, stride=2)\n",
    "        self.t_conv5 = nn.ConvTranspose2d(2, 1, 2, stride=2)\n",
    "\n",
    "    def forward(self, x, get_hidden = False):\n",
    "        ## encode ##\n",
    "        # add hidden layers with relu activation function\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        if get_hidden:\n",
    "            return torch.flatten(x)\n",
    "        \n",
    "        ## decode ##\n",
    "        x = F.relu(self.t_conv4(x)) # output layer (with sigmoid for scaling from 0 to 1)\n",
    "        x = torch.sigmoid(self.t_conv5(x)) # output layer (with sigmoid for scaling from 0 to 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ここからVAE (2020.06.24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseVAE(nn.Module):\n",
    "    def __init__(self, img_size=128, z_dim=64):\n",
    "        super().__init__()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.linear1 = nn.Linear(img_size ** 2, 4096)\n",
    "        self.linear2 = nn.Linear(4096, 1024)\n",
    "        \n",
    "        self.linear_mean = nn.Linear(1024, z_dim)\n",
    "        self.linear_logvar = nn.Linear(1024, z_dim)\n",
    "        \n",
    "        self.dec_linear3 = nn.Linear(z_dim, 1024)\n",
    "        self.dec_linear2 = nn.Linear(1024, 4096)\n",
    "        self.dec_linear1 = nn.Linear(4096, img_size ** 2)\n",
    "    \n",
    "    def encoder(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        mean = self.linear_mean(x)\n",
    "        logvar = F.softplus(self.linear_logvar(x))\n",
    "        return mean, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decoder(self, z):\n",
    "        x = F.relu(self.dec_linear3(z))\n",
    "        x = F.relu(self.dec_linear2(x))\n",
    "        x = torch.sigmoid(self.dec_linear1(x))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decoder(z), mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseVAE_2dim(nn.Module):\n",
    "    def __init__(self, img_size=128, z_dim=2):\n",
    "        super().__init__()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.linear1 = nn.Linear(img_size ** 2, 4096)\n",
    "        self.linear2 = nn.Linear(4096, 1024)\n",
    "        self.linear3 = nn.Linear(1024, 256)\n",
    "        self.linear4 = nn.Linear(256, 64)\n",
    "        self.linear5 = nn.Linear(64, 16)\n",
    "        \n",
    "        self.linear_mean = nn.Linear(16, z_dim)\n",
    "        self.linear_logvar = nn.Linear(16, z_dim)\n",
    "        \n",
    "        self.dec_linear6 = nn.Linear(z_dim, 16)\n",
    "        self.dec_linear5 = nn.Linear(16, 64)\n",
    "        self.dec_linear4 = nn.Linear(64, 256)\n",
    "        self.dec_linear3 = nn.Linear(256, 1024)\n",
    "        self.dec_linear2 = nn.Linear(1024, 4096)\n",
    "        self.dec_linear1 = nn.Linear(4096, img_size ** 2)\n",
    "    \n",
    "    def encoder(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = F.relu(self.linear3(x))\n",
    "        x = F.relu(self.linear4(x))\n",
    "        x = F.relu(self.linear5(x))\n",
    "        mean = self.linear_mean(x)\n",
    "        logvar = F.softplus(self.linear_logvar(x))\n",
    "        return mean, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decoder(self, z):\n",
    "        x = F.relu(self.dec_linear6(z))\n",
    "        x = F.relu(self.dec_linear5(x))\n",
    "        x = F.relu(self.dec_linear4(x))\n",
    "        x = F.relu(self.dec_linear3(x))\n",
    "        x = F.relu(self.dec_linear2(x))\n",
    "        x = torch.sigmoid(self.dec_linear1(x))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decoder(z), mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvVAE(nn.Module):\n",
    "    def __init__(self, img_size=128, z_dim=64):\n",
    "        super().__init__()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5, padding=2, stride=2) # conv layer, 5x5 kernels, input: 1 * 128 * 128, output: 16 * 64 * 64\n",
    "        self.conv2 = nn.Conv2d(16, 64, kernel_size=5, padding=2, stride=2) # conv layer, 5x5 kernels, input: 16 * 64 * 64, output: 64 * 32 * 32\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=5, padding=2, stride=2) # conv layer, 5x5 kernels, input: 64 * 32 * 32, output: 128 * 16 * 16\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1, stride=2) # conv layer, 3x3 kernels, input:128 * 16 * 16, output: 256 * 8 * 8\n",
    "        self.conv5 = nn.Conv2d(256, 512, kernel_size=3, padding=1, stride=2) # conv layer, 3x3 kernels, input: 256 * 8 * 8, output: 512 * 4 * 4\n",
    "        self.conv6 = nn.Conv2d(512, 1024, kernel_size=4) # conv layer, 4x4 kernels, input: 512 * 4 * 4, output: 1024 * 1 * 1\n",
    "        \n",
    "        self.conv_mean = nn.Conv2d(1024, z_dim, kernel_size=1)\n",
    "        self.conv_var = nn.Conv2d(1024, z_dim, kernel_size=1)\n",
    "        \n",
    "        self.t_conv7 = nn.ConvTranspose2d(z_dim, 1024, kernel_size=1, stride=1)\n",
    "        self.t_conv6 = nn.ConvTranspose2d(1024, 512, kernel_size=4, stride=1)\n",
    "        self.t_conv5 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2)\n",
    "        self.t_conv4 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2)\n",
    "        self.t_conv3 = nn.ConvTranspose2d(128, 64, kernel_size=5, stride=2)\n",
    "        self.t_conv2 = nn.ConvTranspose2d(64, 16, kernel_size=5, stride=2)\n",
    "        self.t_conv1 = nn.ConvTranspose2d(16, 1, kernel_size=5, stride=2)\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        mean = self.conv_mean(x)\n",
    "        logvar = F.softplus(self.conv_var(x))\n",
    "        return mean, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decoder(self, z):\n",
    "        x = F.relu(self.t_conv7(z))\n",
    "        x = F.relu(self.t_conv6(x))\n",
    "        x = F.relu(self.t_conv5(x))[:, :, :-1, :-1]\n",
    "        x = F.relu(self.t_conv4(x))[:, :, :-1, :-1]\n",
    "        x = F.relu(self.t_conv3(x))[:, :, 1:-2, 1:-2]\n",
    "        x = F.relu(self.t_conv2(x))[:, :, 1:-2, 1:-2]\n",
    "        x = torch.sigmoid(self.t_conv1(x))[:, :, 1:-2, 1:-2]\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decoder(z), mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvVAE_224(nn.Module):\n",
    "    def __init__(self, img_size=128, z_dim=64):\n",
    "        super().__init__()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5, padding=2, stride=2) # conv layer, 5x5 kernels, input: 1 * 224 * 224, output: 16 * 112 * 112\n",
    "        self.conv2 = nn.Conv2d(16, 64, kernel_size=5, padding=2, stride=2) # conv layer, 5x5 kernels, input: 16 * 112 * 112, output: 64 * 56 * 56\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=5, padding=2, stride=2) # conv layer, 5x5 kernels, input: 64 * 56 * 56, output: 128 * 28 * 28\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1, stride=2) # conv layer, 3x3 kernels, input: 128 * 28 * 28, output: 256 *14 * 14\n",
    "        self.conv5 = nn.Conv2d(256, 512, kernel_size=3, padding=1, stride=2) # conv layer, 3x3 kernels, input: 256 * 14 * 14, output: 512 * 7 * 7\n",
    "        self.conv6 = nn.Conv2d(512, 1024, kernel_size=7) # conv layer, 4x4 kernels, input: 512 * 7 * 7, output:  * 1 * 1\n",
    "        \n",
    "        self.conv_mean = nn.Conv2d(1024, z_dim, kernel_size=1)\n",
    "        self.conv_var = nn.Conv2d(1024, z_dim, kernel_size=1)\n",
    "        \n",
    "        self.t_conv7 = nn.ConvTranspose2d(z_dim, 1024, kernel_size=1, stride=1)\n",
    "        self.t_conv6 = nn.ConvTranspose2d(1024, 512, kernel_size=7, stride=1)\n",
    "        self.t_conv5 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2)\n",
    "        self.t_conv4 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2)\n",
    "        self.t_conv3 = nn.ConvTranspose2d(128, 64, kernel_size=5, stride=2)\n",
    "        self.t_conv2 = nn.ConvTranspose2d(64, 16, kernel_size=5, stride=2)\n",
    "        self.t_conv1 = nn.ConvTranspose2d(16, 1, kernel_size=5, stride=2)\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        mean = self.conv_mean(x)\n",
    "        logvar = F.softplus(self.conv_var(x))\n",
    "        return mean, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decoder(self, z):\n",
    "        x = F.relu(self.t_conv7(z))\n",
    "        x = F.relu(self.t_conv6(x))\n",
    "        x = F.relu(self.t_conv5(x))[:, :, :-1, :-1]\n",
    "        x = F.relu(self.t_conv4(x))[:, :, :-1, :-1]\n",
    "        x = F.relu(self.t_conv3(x))[:, :, 1:-2, 1:-2]\n",
    "        x = F.relu(self.t_conv2(x))[:, :, 1:-2, 1:-2]\n",
    "        x = torch.sigmoid(self.t_conv1(x))[:, :, 1:-2, 1:-2]\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decoder(z), mu, logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAE_mnist2(nn.Module):\n",
    "    def  __init__(self, embedding_dimension):\n",
    "        super().__init__()\n",
    "\n",
    "        # encoder\n",
    "        self.conv1 = nn.Sequential(nn.ZeroPad2d((1,2,1,2)),\n",
    "                                                    nn.Conv2d(1, 32, kernel_size=5, stride=2),\n",
    "                                                    nn.ReLU())\n",
    "        self.conv2 = nn.Sequential(nn.ZeroPad2d((1,2,1,2)),\n",
    "                                                    nn.Conv2d(32, 64, kernel_size=5, stride=2),\n",
    "                                                    nn.ReLU())\n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=0),\n",
    "                                                    nn.ReLU())\n",
    "        self.fc1 = nn.Conv2d(128, 10, kernel_size=3)\n",
    "\n",
    "        # decoder\n",
    "        self.fc2 = nn.Sequential(nn.ConvTranspose2d(10, 128, kernel_size=3),\n",
    "                                               nn.ReLU())\n",
    "        self.conv3d = nn.Sequential(nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=0),\n",
    "                                                      nn.ReLU())\n",
    "        self.conv2d = nn.Sequential(nn.ConvTranspose2d(64, 32, kernel_size=5, stride=2),\n",
    "                                                      nn.ReLU())\n",
    "        self.conv1d = nn.ConvTranspose2d(32, 1, kernel_size=5, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.fc1(self.conv3(self.conv2(self.conv1(x))))\n",
    "\n",
    "        decoded = self.fc2(encoded)\n",
    "        decoded = self.conv3d(decoded)\n",
    "        decoded = self.conv2d(decoded)[:,:,1:-2,1:-2]\n",
    "        decoded = self.conv1d(decoded)[:,:,1:-2,1:-2]\n",
    "        decoded = nn.Sigmoid()(decoded)\n",
    "\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['jupyter', 'nbconvert', '--to', 'python', 'vae_models.ipynb'], returncode=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.run(['jupyter', 'nbconvert', '--to', 'python', 'vae_models.ipynb'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
